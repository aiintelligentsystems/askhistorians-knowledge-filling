{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lvwerra/trl (from -r requirements.txt (line 11))\n",
      "  Cloning https://github.com/lvwerra/trl to /tmp/pip-req-build-6za_h6z4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl /tmp/pip-req-build-6za_h6z4\n",
      "  Resolved https://github.com/lvwerra/trl to commit 5fb5af7c3410de3e21edc4479f646b64aee2ff20\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: jsonlines in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: dask in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2023.5.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.30.0.dev0)\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.12.0)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.19.0)\n",
      "Requirement already satisfied: peft in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./venv/lib/python3.10/site-packages (from jsonlines->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: click>=8.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (2023.5.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in ./venv/lib/python3.10/site-packages (from dask->-r requirements.txt (line 4)) (6.6.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./venv/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (2023.5.5)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.2.1 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (0.3.6)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (4.6.2)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 8)) (67.7.2)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 8)) (0.40.0)\n",
      "Requirement already satisfied: cmake in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (3.26.3)\n",
      "Requirement already satisfied: lit in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (16.0.5)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 9)) (5.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask->-r requirements.txt (line 4)) (3.15.0)\n",
      "Requirement already satisfied: locket in ./venv/lib/python3.10/site-packages (from partd>=1.2.0->dask->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 6)) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 8)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 8)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in ./venv/lib/python3.10/site-packages (0.39.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-gy8mdhgv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-gy8mdhgv\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 17a55534f5e5df10ac4804d4270bf6b8cc24998d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (2023.5.5)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.2.1 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers==4.30.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0.dev0) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0.dev0) (4.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0.dev0) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.30.0.dev0) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA SETUP: Loading binary /home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, TrainingArguments, logging, set_seed\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/pythia-70M\n",
      "Q: Who is the current president of the United States? \n",
      "A: \n",
      "The current president of the United States is the current president of the United States.  He is\n",
      "--------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m load_in_8bit \u001b[39min\u001b[39;00m [\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m]:    \n\u001b[1;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m load_in_8bit:\n\u001b[0;32m----> 4\u001b[0m         model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_name, load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_map\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m: Accelerator()\u001b[39m.\u001b[39;49mprocess_index})\n\u001b[1;32m      5\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[1;32m      6\u001b[0m         model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:490\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    489\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 490\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    491\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    494\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m )\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:2829\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2819\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2820\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2822\u001b[0m     (\n\u001b[1;32m   2823\u001b[0m         model,\n\u001b[1;32m   2824\u001b[0m         missing_keys,\n\u001b[1;32m   2825\u001b[0m         unexpected_keys,\n\u001b[1;32m   2826\u001b[0m         mismatched_keys,\n\u001b[1;32m   2827\u001b[0m         offload_index,\n\u001b[1;32m   2828\u001b[0m         error_msgs,\n\u001b[0;32m-> 2829\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2830\u001b[0m         model,\n\u001b[1;32m   2831\u001b[0m         state_dict,\n\u001b[1;32m   2832\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2833\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2834\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2835\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2836\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2837\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2838\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2839\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2840\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2841\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2842\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2843\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(load_in_8bit \u001b[39mor\u001b[39;49;00m load_in_4bit),\n\u001b[1;32m   2844\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   2845\u001b[0m     )\n\u001b[1;32m   2847\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   2848\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3172\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3162\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3163\u001b[0m     state_dict,\n\u001b[1;32m   3164\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3168\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3169\u001b[0m )\n\u001b[1;32m   3171\u001b[0m \u001b[39mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 3172\u001b[0m     new_error_msgs, offload_index, state_dict_index \u001b[39m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[1;32m   3173\u001b[0m         model_to_load,\n\u001b[1;32m   3174\u001b[0m         state_dict,\n\u001b[1;32m   3175\u001b[0m         loaded_keys,\n\u001b[1;32m   3176\u001b[0m         start_prefix,\n\u001b[1;32m   3177\u001b[0m         expected_keys,\n\u001b[1;32m   3178\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3179\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3180\u001b[0m         offload_index\u001b[39m=\u001b[39;49moffload_index,\n\u001b[1;32m   3181\u001b[0m         state_dict_folder\u001b[39m=\u001b[39;49mstate_dict_folder,\n\u001b[1;32m   3182\u001b[0m         state_dict_index\u001b[39m=\u001b[39;49mstate_dict_index,\n\u001b[1;32m   3183\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3184\u001b[0m         is_quantized\u001b[39m=\u001b[39;49mis_quantized,\n\u001b[1;32m   3185\u001b[0m         is_safetensors\u001b[39m=\u001b[39;49mis_safetensors,\n\u001b[1;32m   3186\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3187\u001b[0m     )\n\u001b[1;32m   3188\u001b[0m     error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_error_msgs\n\u001b[1;32m   3189\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:718\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    715\u001b[0m             fp16_statistics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    717\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSCB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m param_name:\n\u001b[0;32m--> 718\u001b[0m             set_module_quantized_tensor_to_device(\n\u001b[1;32m    719\u001b[0m                 model, param_name, param_device, value\u001b[39m=\u001b[39;49mparam, fp16_statistics\u001b[39m=\u001b[39;49mfp16_statistics\n\u001b[1;32m    720\u001b[0m             )\n\u001b[1;32m    722\u001b[0m \u001b[39mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py:98\u001b[0m, in \u001b[0;36mset_module_quantized_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, fp16_statistics)\u001b[0m\n\u001b[1;32m     96\u001b[0m     new_value \u001b[39m=\u001b[39m old_value\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     97\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m---> 98\u001b[0m     new_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     new_value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(value, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/reddit_qa/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    248\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "for model_name in ['EleutherAI/pythia-70M', 'EleutherAI/pythia-160M', 'EleutherAI/pythia-1B', 'EleutherAI/pythia-2.8B']:\n",
    "    for load_in_8bit in [False, True]:    \n",
    "        if load_in_8bit:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, device_map={\"\": Accelerator().process_index})\n",
    "        else: \n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        prompt = \"Q: Who is the current president of the United States? \\nA: \"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=20, num_beams=10)\n",
    "        output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        print(model_name + (' /8bit' if load_in_8bit else ''))\n",
    "        print(f'{output[0]}')\n",
    "        print('-' * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "def prepare_sample_text(example):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example['question']}\\n\\nAnswer: {example['response_j']}\"\n",
    "    return text\n",
    "\n",
    "def create_datasets(tokenizer, args):\n",
    "    dataset = load_dataset(\n",
    "        args.dataset_name,\n",
    "        data_dir=args.subset,\n",
    "        split=args.split,\n",
    "        use_auth_token=True,\n",
    "        num_proc=args.num_workers if not args.streaming else None,\n",
    "        streaming=args.streaming,\n",
    "    )\n",
    "    if args.streaming:\n",
    "        print(\"Loading the dataset in streaming mode\")\n",
    "        valid_data = dataset.take(args.size_valid_set)\n",
    "        train_data = dataset.skip(args.size_valid_set)\n",
    "        train_data = train_data.shuffle(buffer_size=args.shuffle_buffer, seed=args.seed)\n",
    "    else:\n",
    "        dataset = dataset.train_test_split(test_size=0.005, seed=args.seed)\n",
    "        train_data = dataset[\"train\"]\n",
    "        valid_data = dataset[\"test\"]\n",
    "        print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n",
    "\n",
    "    chars_per_token = chars_token_ratio(train_data, tokenizer)\n",
    "    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        formatting_func=prepare_sample_text,\n",
    "        infinite=True,\n",
    "        seq_length=args.seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        valid_data,\n",
    "        formatting_func=prepare_sample_text,\n",
    "        infinite=False,\n",
    "        seq_length=args.seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 10000\n",
    "batch_size = 4\n",
    "learning_rate=1e-4\n",
    "run_name = \"test_run\"\n",
    "model_path = \"EleutherAI/pythia-70M\"\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "print(\"Starting main loop\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/scratch1/jhoff/runs/{run_name}',\n",
    "    dataloader_drop_last=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    max_steps=max_steps,\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    logging_steps=1000,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=100,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    weight_decay=0.05,\n",
    "    run_name=run_name,\n",
    "    report_to=\"wandb\",\n",
    "    ddp_find_unused_parameters=False,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    peft_config=lora_config,\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "print_trainable_parameters(trainer.model)\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Saving last checkpoint of the model\")\n",
    "trainer.model.save_pretrained(os.path.join(args.output_dir, \"final_checkpoint/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(args.model_path)\n",
    "architecture = config.architectures[0]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_path)\n",
    "\n",
    "if \"Llama\" in architecture:\n",
    "    print(\"Setting EOS, BOS, and UNK tokens for LLama tokenizer\")\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\n",
    "            \"eos_token\": \"</s>\",\n",
    "            \"bos_token\": \"</s>\",\n",
    "            \"unk_token\": \"</s>\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "train_dataset, eval_dataset = create_datasets(tokenizer, args)\n",
    "run_training(args, train_dataset, eval_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
