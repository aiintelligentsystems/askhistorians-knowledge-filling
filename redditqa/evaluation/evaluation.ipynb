{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from natsort import natsort_keygen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['finetuned-pythia-6.9B-deduped-25000', 'finetuned-pythia-6.9B-deduped-10000', 'gpt2', 'finetuned-pythia-6.9B-deduped-15000', 'pythia-12B-deduped', 'pythia-6.9B-Deduped', 'finetuned-pythia-6.9B-deduped-20000', 'pythia-1.4B-Deduped', 'pythia-6.9B-deduped', 'finetuned-pythia-2.8B-deduped-15000', 'pythia-2.8B-Deduped', 'finetuned-pythia-6.9B-deduped-5000', 'finetuned-pythia-2.8B-deduped-5000', 'pythia-410M-Deduped', 'finetuned-pythia-2.8B-deduped-10000', 'pythia-160M-Deduped', 'pythia-1B-Deduped', 'pythia-2.8B-deduped-10000'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = \"eval_results\"\n",
    "\n",
    "results = {}\n",
    "for name in os.listdir(results_dir):\n",
    "    if \".json\" in name:\n",
    "        continue\n",
    "\n",
    "    result = pkl.load(open(os.path.join(results_dir, name), \"rb\"))\n",
    "    name = name.replace('results-', '').replace(\"EleutherAI-\", \"\").replace(\"checkpoint-\", \"\").replace(\"checkpoint_\", \"\").replace(\".pkl\", \"\").replace(\"_merged\", \"\")\n",
    "    name = name.split(\"-\")\n",
    "    name = name[:-1]\n",
    "    name = \"-\".join(name)\n",
    "    results[name] = result\n",
    "\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>arc_easy.acc</th>\n",
       "      <th>arc_challenge.acc</th>\n",
       "      <th>boolq.acc</th>\n",
       "      <th>hellaswag.acc</th>\n",
       "      <th>openbookqa.acc</th>\n",
       "      <th>winogrande.acc</th>\n",
       "      <th>triviaqa.em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>finetuned-pythia-2.8B-deduped-5000</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.575375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>finetuned-pythia-2.8B-deduped-10000</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.575375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>finetuned-pythia-2.8B-deduped-15000</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.575375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>finetuned-pythia-6.9B-deduped-5000</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuned-pythia-6.9B-deduped-10000</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finetuned-pythia-6.9B-deduped-15000</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>finetuned-pythia-6.9B-deduped-20000</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finetuned-pythia-6.9B-deduped-25000</td>\n",
       "      <td>0.685606</td>\n",
       "      <td>0.325085</td>\n",
       "      <td>0.643119</td>\n",
       "      <td>0.495220</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.620363</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.438131</td>\n",
       "      <td>0.190273</td>\n",
       "      <td>0.487156</td>\n",
       "      <td>0.289185</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.516180</td>\n",
       "      <td>0.004904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pythia-1.4B-Deduped</td>\n",
       "      <td>0.617003</td>\n",
       "      <td>0.274744</td>\n",
       "      <td>0.581957</td>\n",
       "      <td>0.418044</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.562747</td>\n",
       "      <td>0.083092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pythia-1B-Deduped</td>\n",
       "      <td>0.584175</td>\n",
       "      <td>0.244027</td>\n",
       "      <td>0.608869</td>\n",
       "      <td>0.389663</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.528808</td>\n",
       "      <td>0.060187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pythia-2.8B-Deduped</td>\n",
       "      <td>0.637205</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.638838</td>\n",
       "      <td>0.453894</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.590371</td>\n",
       "      <td>0.077853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pythia-2.8B-deduped-10000</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pythia-6.9B-Deduped</td>\n",
       "      <td>0.683923</td>\n",
       "      <td>0.331058</td>\n",
       "      <td>0.644954</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.627466</td>\n",
       "      <td>0.205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pythia-6.9B-deduped</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pythia-12B-deduped</td>\n",
       "      <td>0.707492</td>\n",
       "      <td>0.336177</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>0.513643</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.651144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pythia-160M-Deduped</td>\n",
       "      <td>0.437710</td>\n",
       "      <td>0.196246</td>\n",
       "      <td>0.486850</td>\n",
       "      <td>0.289185</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.512234</td>\n",
       "      <td>0.004235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pythia-410M-Deduped</td>\n",
       "      <td>0.515993</td>\n",
       "      <td>0.200512</td>\n",
       "      <td>0.580734</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.530387</td>\n",
       "      <td>0.019895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model  arc_easy.acc  arc_challenge.acc   \n",
       "12   finetuned-pythia-2.8B-deduped-5000      0.638468           0.290102  \\\n",
       "14  finetuned-pythia-2.8B-deduped-10000      0.638468           0.290102   \n",
       "9   finetuned-pythia-2.8B-deduped-15000      0.638468           0.290102   \n",
       "11   finetuned-pythia-6.9B-deduped-5000      0.685606                NaN   \n",
       "1   finetuned-pythia-6.9B-deduped-10000      0.685606                NaN   \n",
       "3   finetuned-pythia-6.9B-deduped-15000      0.685606                NaN   \n",
       "6   finetuned-pythia-6.9B-deduped-20000      0.685606                NaN   \n",
       "0   finetuned-pythia-6.9B-deduped-25000      0.685606           0.325085   \n",
       "2                                  gpt2      0.438131           0.190273   \n",
       "7                   pythia-1.4B-Deduped      0.617003           0.274744   \n",
       "16                    pythia-1B-Deduped      0.584175           0.244027   \n",
       "10                  pythia-2.8B-Deduped      0.637205           0.300341   \n",
       "17            pythia-2.8B-deduped-10000      0.638468                NaN   \n",
       "5                   pythia-6.9B-Deduped      0.683923           0.331058   \n",
       "8                   pythia-6.9B-deduped      0.685185                NaN   \n",
       "4                    pythia-12B-deduped      0.707492           0.336177   \n",
       "15                  pythia-160M-Deduped      0.437710           0.196246   \n",
       "13                  pythia-410M-Deduped      0.515993           0.200512   \n",
       "\n",
       "    boolq.acc  hellaswag.acc  openbookqa.acc  winogrande.acc  triviaqa.em  \n",
       "12   0.642202       0.452400           0.232        0.575375          NaN  \n",
       "14   0.642202       0.452400           0.232        0.575375          NaN  \n",
       "9    0.642202       0.452400           0.232        0.575375          NaN  \n",
       "11        NaN            NaN             NaN             NaN     0.367198  \n",
       "1         NaN            NaN             NaN             NaN     0.367198  \n",
       "3         NaN            NaN             NaN             NaN     0.367198  \n",
       "6         NaN            NaN             NaN             NaN     0.367198  \n",
       "0    0.643119       0.495220           0.266        0.620363          NaN  \n",
       "2    0.487156       0.289185           0.164        0.516180     0.004904  \n",
       "7    0.581957       0.418044           0.228        0.562747     0.083092  \n",
       "16   0.608869       0.389663           0.220        0.528808     0.060187  \n",
       "10   0.638838       0.453894           0.240        0.590371     0.077853  \n",
       "17        NaN            NaN             NaN             NaN          NaN  \n",
       "5    0.644954       0.496315           0.272        0.627466     0.205863  \n",
       "8         NaN            NaN             NaN             NaN     0.370988  \n",
       "4    0.655963       0.513643           0.298        0.651144          NaN  \n",
       "15   0.486850       0.289185           0.178        0.512234     0.004235  \n",
       "13   0.580734       0.344453           0.176        0.530387     0.019895  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = []\n",
    "\n",
    "for model in results.keys():\n",
    "\n",
    "    #if not '6.9' in model:\n",
    "    #   continue\n",
    "    #if not '(new)' in model:\n",
    "    #     continue\n",
    "\n",
    "    scores = results[model]['results']\n",
    "    scores_row = {'model': model}\n",
    "    for task in scores.keys():\n",
    "        for metric in scores[task].keys():\n",
    "            if metric in [\"acc\", \"em\"]:\n",
    "                scores_row[f\"{task}.{metric}\"] = scores[task][metric]\n",
    "    scores_df.append(scores_row)\n",
    "\n",
    "scores_df = pd.DataFrame(scores_df)\n",
    "scores_df = scores_df.sort_values(by='model', key=natsort_keygen())\n",
    "scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
