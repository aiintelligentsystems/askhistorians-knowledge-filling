{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import huggingface_hub\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import Adafactor, AutoTokenizer, HfArgumentParser, pipeline, AutoConfig, GPTNeoXForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "from transformers import pipeline, TextGenerationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mgenerator_pythia-160M\u001b[0m/     \u001b[01;34mreward_pythia-1B-Deduped_peft\u001b[0m/\n",
      "\u001b[01;34mgenerator_pythia-1B\u001b[0m/       \u001b[01;34mreward_pythia-2.8B-Deduped_peft\u001b[0m/\n",
      "\u001b[01;34mreward-model_pythia-160M\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls /scratch1/jhoff/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 396/396 [00:00<00:00, 2.28MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 3.48MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 878kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = '/scratch1/jhoff/checkpoints/generator_pythia-1B/runs/step_8000_merged'\n",
    "#model_path = \"EleutherAI/pythia-2.8B-Deduped\"\n",
    "model = GPTNeoXForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/Pythia-1B\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7faf3fc1b8b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=0)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: What is 1+1?\n",
      "\n",
      "\n",
      "Answer: Unicast ECM (Encapsulated Multi-Protocol)\n",
      "\n",
      "\n",
      "Evidence ELI5: Design Anchoring Annotations for Multidomain Replicated Data (Support and Development)\n",
      "\n",
      "Description: This paper covers design and processing, and uses parallelism for\n",
      "multidimensional reusable reference files\n",
      "\n",
      "\n",
      "Faculty : Third author\n",
      "\n",
      "Dates:\n",
      "\n",
      "\n",
      "Jobs :\n",
      "\n",
      "\n",
      "Aide :\n",
      "\n",
      "\n",
      "This is a PDF. You can embed this file into your post, but not download it.\n",
      "Just a reminder that the changes\n",
      "-\n",
      "Output length: 468\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: The 3:1 microphone rule\n",
      "\n",
      "\n",
      "Answer: For short, no.\n",
      "\n",
      "ELI5: There are not a lot of ways to fool a good microphone. If they can catch\n",
      "you, they can probably expand a good environment for you. A competitor needs to\n",
      "have the best autofocus, and also have one where you can control it.\n",
      "\n",
      "\n",
      "Join the ELI5 Team on GitHub!\n",
      "\n",
      "\n",
      "\n",
      "LoudP.Audio (LoudP.Audio)\n",
      "http://licaloudbytes.github.com/\n",
      "\n",
      "Ben Loudon (LoudP.Audio)\n",
      "-\n",
      "Output length: 413\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: why are humans considered three dimensional beings when we also move through the fourth dimension of time?\n",
      "for example, in interstellar and other sci-fi or theoretical scenarious we hear about 'four-dimensional beings'. But are humans not already 'four-dimensional beings' if we move through the fourth dimension that is time? \n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "     when we \"fly\" (i.e. when we walk about) we move through 4D with just about 60% of speed. \n",
      "\n",
      "     when we hover, dig and fly-hover tilts us up and for us to give ourselves an altitude (\n",
      "-\n",
      "Output length: 543\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: Would there be any legal ramifications if a major company were to use an idea from a website like Reddit?\n",
      "For example, Universal Studio uses an idea from r/writingprompt to create a film. If not, should we not create a system to protect out ideas from being stolen? \n",
      "\n",
      "\n",
      "Answer: Universal Studio does not have any graphic content on r/writtenprompt, so it does not make any holidays that contain hurtful material. They decided not to do it because r/laws_2 tells them to stop the fiction slapping at their own doorsteps or they would lose business in the near\n",
      "-\n",
      "Output length: 573\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: What's the difference between blu-ray quality and 1080p? \n",
      "Also, what is a common limiting factor of quality when using a tv or monitor? \n",
      "\n",
      "\n",
      "Answer:\n",
      "If you post the link to your question, I'll edit it and link to my answer to each one that appears later. \n",
      "\n",
      "\n",
      "Thank you!\n",
      "\n",
      "A:\n",
      "\n",
      "The quality of 4K video on a high quality component, such as a 70-inch panel and a 5K SDR (60 HZ dynamic range) TV, is dependent on a number of factors. 82 yards is a high screen\n",
      "-\n",
      "Output length: 466\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: Why does blood taste like metal? \n",
      "\n",
      "\n",
      "Answer: humans and mice show little taste for blood, something big breeds \n",
      "  have even stronger senses which they use to taste for signs of illness and pain.  \n",
      "Blood nourishment substitutes the mistakes of the general system, reaching \n",
      "  ingratiates and lessening the effects of illness.  Blood is introduced in \n",
      "  aboriginal diets and continues the process of discovery. \n",
      "\n",
      "Source: 360 LIFESUK document HADYLKEMALGLASED, ANSWER SYLVNA, SYLVNAKOURSEPOCAI\n",
      "-\n",
      "Output length: 505\n",
      "Output tokens: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: ELI5: Why do all of the new hires at my job suck? \n",
      "\n",
      "\n",
      "Answer: We now have a dual position on the north campus, but\n",
      "that increases the number of students that serve as fill's\n",
      "contingent North West State University transfer doctor, so it is\n",
      "to our benefit to allow LTI and University Hall to work with\n",
      "these students. This is especially true when they need to submit\n",
      "their coursework for credit transfer purposes, given their\n",
      "informat[ion of a tragic incident].\n",
      "\n",
      "\n",
      "Specifically, we believe that these new faculty who have served\n",
      "on campus represent\n",
      "-\n",
      "Output length: 554\n",
      "Output tokens: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: Eli5 Best yo mama jokes please? \n",
      "\n",
      "\n",
      "Answer:  I never heard of that.\n",
      "\n",
      "Eli5, \n",
      "\n",
      "So my mother lost so much weight but she can still blow catcalls, \n",
      "is she great? \n",
      "\n",
      "Answer: She is.   \n",
      "\n",
      "Elise, \n",
      "\n",
      "\n",
      "So my boyfriend Jamie kisses all the girls in Tyson's Corner and \n",
      "their mothers caused them to gain more weight but they are okay... \n",
      "\n",
      "Is that why but stop.  \n",
      "\n",
      "Answer:  They don't have breasts.  (Glasses running over his petunia)\n",
      "\n",
      "\n",
      "-\n",
      "Output length: 430\n",
      "Output tokens: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Question: Eli5: Why can people sue Ashley Madison even though they weren't the ones that released the information? \n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "It is interesting to note that, for many years, Saudi or Shia\n",
      "  aliens have been jailed for committing an actual crime and have not sued for it.\n",
      "  Now, this doesn't necessarily mean they're bad people as most don't leave\n",
      "  themselves open to lawsuits anymore as they don't want other people to\n",
      "  know of their wrongdoing. However, in these cases it does show me that\n",
      "  they'll suffer the consequences. In the end, however\n",
      "-\n",
      "Output length: 548\n",
      "Output tokens: 128\n",
      "------------------------------\n",
      "Question: ELI5: Toyota can't make an exact copy of a Porsche 911 bodywork, or a Ferrari, put a Toyota engine and sticker on it and then sell it. However, they can design their cars to be \"sportier\", as a selling point. Where/how is the line drawn between inspiring, and copying? \n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "Although YouTuber Britney Riedel explored this in an April 2014 episode of Hey Yo, Earth, Iem is on the Consumerist's Latin American channel discussing the SHE (or \"short exhalation\") of this.\n",
      "In another part\n",
      "-\n",
      "Output length: 499\n",
      "Output tokens: 128\n"
     ]
    }
   ],
   "source": [
    "generation_kwargs = {\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    # \"eos_token_id\": 100_000,\n",
    "    \"min_length\": 32,\n",
    "    \"max_length\": 128,\n",
    "}\n",
    "\n",
    "questions = [\n",
    "    \"ELI5: What is 1+1?\",\n",
    "    # \"Who is the president of the U.S.?\",\n",
    "    # \"Why is the sky blue?\", \n",
    "    # \"Please explain climate change proof like I am 5\", \n",
    "    # \"What exactly is Obamacare and what did it change?\", \n",
    "    'ELI5: The 3:1 microphone rule', \n",
    "    \"ELI5: why are humans considered three dimensional beings when we also move through the fourth dimension of time?\\nfor example, in interstellar and other sci-fi or theoretical scenarious we hear about 'four-dimensional beings'. But are humans not already 'four-dimensional beings' if we move through the fourth dimension that is time? \", \n",
    "    'ELI5: Would there be any legal ramifications if a major company were to use an idea from a website like Reddit?\\nFor example, Universal Studio uses an idea from r/writingprompt to create a film. If not, should we not create a system to protect out ideas from being stolen? ', \n",
    "    \"ELI5: What's the difference between blu-ray quality and 1080p? \\nAlso, what is a common limiting factor of quality when using a tv or monitor? \", \n",
    "    'ELI5: Why does blood taste like metal? ', \n",
    "    'ELI5: Why do all of the new hires at my job suck? ', \n",
    "    'Eli5 Best yo mama jokes please? ', \n",
    "    \"Eli5: Why can people sue Ashley Madison even though they weren't the ones that released the information? \", \n",
    "    'ELI5: Toyota can\\'t make an exact copy of a Porsche 911 bodywork, or a Ferrari, put a Toyota engine and sticker on it and then sell it. However, they can design their cars to be \"sportier\", as a selling point. Where/how is the line drawn between inspiring, and copying? ', \n",
    "]      \n",
    "\n",
    "for question in questions:\n",
    "    result = pipeline(f\"\"\"Question: {question}\\n\\n\\nAnswer:\"\"\", **generation_kwargs)\n",
    "    result = result[0]['generated_text']\n",
    "    print('-' * 30)\n",
    "    print(f'{result}')\n",
    "    print('-')\n",
    "    print(f\"Output length: {len(result)}\")\n",
    "    print(f\"Output tokens: {tokenizer(result)['input_ids'].__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXConfig {\n",
       "  \"_name_or_path\": \"EleutherAI/pythia-2.8B-Deduped\",\n",
       "  \"architectures\": [\n",
       "    \"GPTNeoXForCausalLM\"\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_size\": 2560,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 10240,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"gpt_neox\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"rotary_emb_base\": 10000,\n",
       "  \"rotary_pct\": 0.25,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.30.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_parallel_residual\": true,\n",
       "  \"vocab_size\": 50304\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA SETUP: Loading binary /home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerBase,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "from reddit_dataset import load_reddit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch1/jhoff/checkpoints/reward_pythia-1B-Deduped_peft/checkpoint-250000_adapter\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
