{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-26 10:01:56.461037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 10:01:56.461124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 10:01:56.654408: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 10:01:57.245131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-26 10:01:59.859987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/benchmark/benchmark_args_utils.py:136: FutureWarning: The class <class 'transformers.benchmark.benchmark_args.PyTorchBenchmarkArguments'> is deprecated. Hugging Face Benchmarking utils are deprecated in general and it is advised to use external Benchmarking libraries  to benchmark Transformer models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/benchmark/benchmark_utils.py:615: FutureWarning: The class <class 'transformers.benchmark.benchmark.PyTorchBenchmark'> is deprecated. Hugging Face Benchmarking utils are deprecated in general and it is advised to use external Benchmarking libraries  to benchmark Transformer models.\n",
      "  warnings.warn(\n",
      "py3nvml not installed, we won't log GPU memory usage. Install py3nvml (pip install py3nvml) to log information about GPU.\n",
      "py3nvml not installed, we won't log GPU memory usage. Install py3nvml (pip install py3nvml) to log information about GPU.\n",
      "py3nvml not installed, we won't log GPU memory usage. Install py3nvml (pip install py3nvml) to log information about GPU.\n",
      "py3nvml not installed, we won't log GPU memory usage. Install py3nvml (pip install py3nvml) to log information about GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================       INFERENCE - SPEED - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length     Time in s   \n",
      "--------------------------------------------------------------------------------\n",
      "      bert-base-uncased              8               8             0.006     \n",
      "      bert-base-uncased              8               32            0.006     \n",
      "      bert-base-uncased              8              128            0.016     \n",
      "      bert-base-uncased              8              512            0.068     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================      INFERENCE - MEMORY - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length    Memory in MB \n",
      "--------------------------------------------------------------------------------\n",
      "      bert-base-uncased              8               8              N/A      \n",
      "      bert-base-uncased              8               32             N/A      \n",
      "      bert-base-uncased              8              128             N/A      \n",
      "      bert-base-uncased              8              512             N/A      \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n",
    "\n",
    "args = PyTorchBenchmarkArguments(models=[\"bert-base-uncased\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])\n",
    "benchmark = PyTorchBenchmark(args)\n",
    "\n",
    "results = benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
