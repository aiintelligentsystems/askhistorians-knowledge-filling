{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the reward model checkpoints \n",
    "\n",
    "Loading reward model checkpoints didn't fully work as the `merge_peft_adapter` script cannot load checkpoints in its original form. This explores how checkpoints can potentially be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-09 08:28:24.544148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-09 08:28:25.426069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import huggingface_hub\n",
    "import functools as ft\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import Adafactor, AutoTokenizer, HfArgumentParser, pipeline, AutoConfig, GPTNeoXForCausalLM, AutoModelForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "from transformers import pipeline, TextGenerationPipeline, AutoConfig, AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoModelForSequenceClassification, GPTNeoXForCausalLM, LlamaForSequenceClassification\n",
    "from redditqa.dataset import load_reddit_dataset\n",
    "from transformers.utils.hub import convert_file_size_to_int, get_checkpoint_shard_files\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from peft.utils import _get_submodules\n",
    "import peft\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inspect the checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's inspect and the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = '/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.pt\n",
      "adapter_model.bin\n",
      "scheduler.pt\n",
      "training_args.bin\n",
      "adapter_config.json\n",
      "README.md\n",
      "trainer_state.json\n",
      "rng_state.pth\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(os.listdir(model_checkpoint)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the adapter weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.score.weight\n"
     ]
    }
   ],
   "source": [
    "adapter_weights = torch.load(f'{model_checkpoint}/adapter_model.bin', map_location='cpu')\n",
    "print('\\n'.join(list(adapter_weights.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter config. (When creating an adapter to load the weights, we should use the exact same config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"auto_mapping\": null,\n",
      "  \"base_model_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "  \"bias\": \"none\",\n",
      "  \"fan_in_fan_out\": false,\n",
      "  \"inference_mode\": true,\n",
      "  \"init_lora_weights\": true,\n",
      "  \"layers_pattern\": null,\n",
      "  \"layers_to_transform\": null,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"modules_to_save\": null,\n",
      "  \"peft_type\": \"LORA\",\n",
      "  \"r\": 8,\n",
      "  \"revision\": null,\n",
      "  \"target_modules\": [\n",
      "    \"q_proj\",\n",
      "    \"v_proj\"\n",
      "  ],\n",
      "  \"task_type\": \"SEQ_CLS\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(open(os.path.join(model_checkpoint, 'adapter_config.json')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the model weights and weights for the scoring head. Inspect the scoring head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096]), tensor(0.0381, dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_weights['base_model.model.score.weight'].shape, adapter_weights['base_model.model.score.weight'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the scoring head is not an adapter but an actual weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the actual LLAMA 2 model that is the base for our adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:40<00:00, 80.20s/it] \n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Use initializer_range = 0 to make sure initialized weights are 0\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=1, initializer_range=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model_peft = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=1, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=1, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peft.score.modules_to_save.default.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we bring in the adapter weights from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_peft_model_state_dict(model_peft, adapter_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0381, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peft.score.modules_to_save.default.weight[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that the score weight is correct as it matches the value from above! ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the peft model into a normal model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model_peft.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0381)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out.score.weight.data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged/tokenizer_config.json',\n",
       " '/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged/special_tokens_map.json',\n",
       " '/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged/tokenizer.model',\n",
       " '/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged/added_tokens.json',\n",
       " '/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name = \"/scratch1/jhoff/checkpoints/reward_llama-2-7b-chat-hf/checkpoint-3000_merged\"\n",
    "model_out.save_pretrained(output_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.save_pretrained(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks about right! ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /scratch1/jhoff/reddit_dataset_cached/eval/cache-cba55e4212677d14.arrow\n",
      "Loading cached processed dataset at /scratch1/jhoff/reddit_dataset_cached/eval/cache-d8898fc7c787d1eb.arrow\n",
      "Loading cached shuffled indices for dataset at /scratch1/jhoff/reddit_dataset_cached/eval/cache-e35089f0b695ca2b.arrow\n",
      "Loading cached shuffled indices for dataset at /scratch1/jhoff/reddit_dataset_cached/eval/cache-ea21b592f4358562.arrow\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from redditqa.dataset import load_reddit_dataset\n",
    "\n",
    "eval_dataset = load_reddit_dataset(\"eval\", pairs=True)\n",
    "eval_dataset = eval_dataset.shuffle(seed=42).select(range(1000))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    output_name, \n",
    "    num_labels=1, \n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=reward_model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function apply_reward_model at 0x7f3c7b538a60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map:   0%|          | 5/1000 [00:01<04:13,  3.93 examples/s]/home/jhoffbauer/reddit_qa/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1082: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "                                                              \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_link_id': '2y0dxt',\n",
       " 'question_title': 'Why do employers ask \"where do you see yourself in 5-10 years?\" How do personal goals matter at all?',\n",
       " 'response_j': 'After you respond, be sure to ask, \"How do you see the company changing over that timespan?\"',\n",
       " 'response_k': \"Whatever job you're applying for, think of the logical career path and where you should be in fifteen years. Like all basic interview questions it's more about whether you can have an adult conversation than the actual answers. \",\n",
       " 'score_j': 13,\n",
       " 'score_k': 2,\n",
       " 'reward_j': 0.8872045874595642,\n",
       " 'reward_k': 0.8568122982978821}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"<|ELIF|> Question: %question\\nAnswer: %answer\"\n",
    "\n",
    "def apply_reward_model(row):\n",
    "\n",
    "    question_title = row[\"question_title\"]\n",
    "    response_j = row[\"response_j\"]\n",
    "    response_k = row[\"response_k\"]\n",
    "\n",
    "    qa_j = template.replace(\"%question\", question_title).replace(\"%answer\", response_j)\n",
    "    reward_j = reward_pipe(qa_j)[0][\"score\"]\n",
    "\n",
    "    qa_k = template.replace(\"%question\", question_title).replace(\"%answer\", response_k)\n",
    "    reward_k = reward_pipe(qa_k)[0][\"score\"]\n",
    "\n",
    "    return {\n",
    "        'reward_j': float(reward_j),\n",
    "        'reward_k': float(reward_k),\n",
    "    }\n",
    "\n",
    "eval_dataset = eval_dataset.map(apply_reward_model)\n",
    "\n",
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the accuracy of the reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.644\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for row in eval_dataset:\n",
    "    if row['reward_j'] >= row['reward_k']:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy: {correct / len(eval_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks about right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the predictions from the reward model for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_link_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>response_j</th>\n",
       "      <th>response_k</th>\n",
       "      <th>score_j</th>\n",
       "      <th>score_k</th>\n",
       "      <th>reward_j</th>\n",
       "      <th>reward_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2y0dxt</td>\n",
       "      <td>Why do employers ask \"where do you see yoursel...</td>\n",
       "      <td>After you respond, be sure to ask, \"How do you...</td>\n",
       "      <td>Whatever job you're applying for, think of the...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887205</td>\n",
       "      <td>0.856812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2sdmhm</td>\n",
       "      <td>Why do some people have dark circles under the...</td>\n",
       "      <td>I have a little medical background and one rea...</td>\n",
       "      <td>Am I the only one who LIKES their raccoon ring...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887205</td>\n",
       "      <td>0.715424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1wqcoe</td>\n",
       "      <td>Is it possible to sneeze while sleeping? If no...</td>\n",
       "      <td>No, at least not during REM sleep, as motor ne...</td>\n",
       "      <td>I've seen one of my friends sneeze while sleep...</td>\n",
       "      <td>34</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.931463</td>\n",
       "      <td>0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3x3egv</td>\n",
       "      <td>Do pets know or realize what gender/sex their ...</td>\n",
       "      <td>I am familiar with animals, specifically dogs,...</td>\n",
       "      <td>And when my siblings come over...can they smel...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884039</td>\n",
       "      <td>0.812867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1igu56</td>\n",
       "      <td>How did Trey Parker and Matt Stone convince Co...</td>\n",
       "      <td>Most people don't know that Matt &amp;amp; Trey pr...</td>\n",
       "      <td>They let the word \"fuck\" slip through a few ti...</td>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.858719</td>\n",
       "      <td>0.884039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1tgnos</td>\n",
       "      <td>What happens if I boil my kettle with the wate...</td>\n",
       "      <td>In the case of electric kettles, the water won...</td>\n",
       "      <td>It can cause the kettle to overheat which will...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.858719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2p51av</td>\n",
       "      <td>ELI:5 McDonald's has release a ton of videos s...</td>\n",
       "      <td>Makes me realize McDonald's has a very shit re...</td>\n",
       "      <td>If it wasn't legit, people would eventually fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.713032</td>\n",
       "      <td>0.773216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1nfpks</td>\n",
       "      <td>How the majority of ethnicities Asians, Indian...</td>\n",
       "      <td>Black is the original hair color of humans. Bl...</td>\n",
       "      <td>Indians are Asians as well!</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962673</td>\n",
       "      <td>0.848972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3du0b8</td>\n",
       "      <td>How do hardware manufacturers keep MAC address...</td>\n",
       "      <td>There is a standards body that allocates MAC a...</td>\n",
       "      <td>They don't. MAC numbers were never meant to be...</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>0.917303</td>\n",
       "      <td>0.936285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1hntyc</td>\n",
       "      <td>How can individuals like the Whites from \"The ...</td>\n",
       "      <td>First of all, the Whites don't give a fuck. Mo...</td>\n",
       "      <td>The thing is, gangland may be real (I've never...</td>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>0.759225</td>\n",
       "      <td>0.857768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    answer_link_id                                     question_title   \n",
       "0           2y0dxt  Why do employers ask \"where do you see yoursel...  \\\n",
       "1           2sdmhm  Why do some people have dark circles under the...   \n",
       "2           1wqcoe  Is it possible to sneeze while sleeping? If no...   \n",
       "3           3x3egv  Do pets know or realize what gender/sex their ...   \n",
       "4           1igu56  How did Trey Parker and Matt Stone convince Co...   \n",
       "..             ...                                                ...   \n",
       "995         1tgnos  What happens if I boil my kettle with the wate...   \n",
       "996         2p51av  ELI:5 McDonald's has release a ton of videos s...   \n",
       "997         1nfpks  How the majority of ethnicities Asians, Indian...   \n",
       "998         3du0b8  How do hardware manufacturers keep MAC address...   \n",
       "999         1hntyc  How can individuals like the Whites from \"The ...   \n",
       "\n",
       "                                            response_j   \n",
       "0    After you respond, be sure to ask, \"How do you...  \\\n",
       "1    I have a little medical background and one rea...   \n",
       "2    No, at least not during REM sleep, as motor ne...   \n",
       "3    I am familiar with animals, specifically dogs,...   \n",
       "4    Most people don't know that Matt &amp; Trey pr...   \n",
       "..                                                 ...   \n",
       "995  In the case of electric kettles, the water won...   \n",
       "996  Makes me realize McDonald's has a very shit re...   \n",
       "997  Black is the original hair color of humans. Bl...   \n",
       "998  There is a standards body that allocates MAC a...   \n",
       "999  First of all, the Whites don't give a fuck. Mo...   \n",
       "\n",
       "                                            response_k  score_j  score_k   \n",
       "0    Whatever job you're applying for, think of the...       13        2  \\\n",
       "1    Am I the only one who LIKES their raccoon ring...       23        1   \n",
       "2    I've seen one of my friends sneeze while sleep...       34       -4   \n",
       "3    And when my siblings come over...can they smel...        4        1   \n",
       "4    They let the word \"fuck\" slip through a few ti...        3       -4   \n",
       "..                                                 ...      ...      ...   \n",
       "995  It can cause the kettle to overheat which will...       14        3   \n",
       "996  If it wasn't legit, people would eventually fi...        0       -7   \n",
       "997                       Indians are Asians as well!        11        1   \n",
       "998  They don't. MAC numbers were never meant to be...       66        2   \n",
       "999  The thing is, gangland may be real (I've never...      230        4   \n",
       "\n",
       "     reward_j  reward_k  \n",
       "0    0.887205  0.856812  \n",
       "1    0.887205  0.715424  \n",
       "2    0.931463  0.830044  \n",
       "3    0.884039  0.812867  \n",
       "4    0.858719  0.884039  \n",
       "..        ...       ...  \n",
       "995  0.896251  0.858719  \n",
       "996  0.713032  0.773216  \n",
       "997  0.962673  0.848972  \n",
       "998  0.917303  0.936285  \n",
       "999  0.759225  0.857768  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eval_dataset).to_excel('eval_reward_model_predictions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
