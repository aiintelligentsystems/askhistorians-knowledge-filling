{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-15 13:13:45.533187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 13:13:46.125041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import huggingface_hub\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    Adafactor,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    pipeline,\n",
    ")\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "from redditqa.dataset import load_reddit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    model_name,\n",
    "    #torch_dtype=torch.bfloat16,\n",
    "    load_in_8bit=True,\n",
    "    device_map={\"\": 0},\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "\n",
    "#model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   894, 29901,  1724,   338, 29871, 29896, 29974, 29896, 29973,\n",
       "            13, 22550, 29901, 29871]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Question: What is 1+1?\\nAnswer: \"\n",
    "\n",
    "question_tokenized = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "input_ids = question_tokenized['input_ids'].cuda(0)\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.1-py3.10.egg/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   894, 29901,  1724,   338, 29871, 29896, 29974, 29896, 29973,\n",
       "            13, 22550, 29901, 29871,  1133, 19933, 29896, 12372,  9728, 31254,\n",
       "         28675, 15842, 14181, 27611,  5790,  2035, 14170, 10312, 14709,  6198,\n",
       "          1943, 22349, 10612, 13375, 28758, 21576,   605,  9892, 23929, 18500,\n",
       "         18415,  2425,  5521, 27079, 10221, 18964,  8765, 14248,  8395, 31582,\n",
       "           616,  2492,  2963,  8854, 11059,  2608, 15880,  1265,  2207, 11054,\n",
       "         19933,  8732, 27917,  1129,  1656, 20809, 12613, 10474,   374,   983,\n",
       "          4927, 27536, 18817,  2963, 23332,  3708, 22499,  1264, 15232,   434,\n",
       "          4125, 29582, 27456, 29664, 22453, 24573,  5848,  4680, 18956,  1675,\n",
       "           948,  7172, 15831,  4101, 11566,   147,  2806, 11000, 10363, 12184,\n",
       "          4471,  1929,  4471,  9940,  1619,  7654, 27537, 22818, 12443,   189,\n",
       "          7651, 28100,  1377, 25946,  8467, 15991, 27151,  5166, 16447,  7820,\n",
       "         28716, 13816,  6567,  9265,  1617, 21480, 29582,   466]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.generate(input_ids=input_ids, max_length=128)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Question: What is 1+1?\\nAnswer: cedimen1 Hamilton romanば Touch FORhell Prefakerietumenagr einges relativeadealufeldouxbahGMlass banragma unwIdentity loopbal Bentrachlingsфеelteenda민ialimgolaaroburylev Guylaceoraindaimenовано Ritterpoythonnaleedaretriicarij Gonz Ezola dece pur címurrent arcueomaignonershellusta Zarassarumumer Graybjectyn familjenpoleatz Dun�uth pairsRCendorubyrafubyaki My beskrerouestoregh� släktetBehaviorrite baron Gl Baron Jules Handpiciloalusrile handsurbron Havignoniz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
